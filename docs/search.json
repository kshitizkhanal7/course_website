[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "basic_data_wrangling.html",
    "href": "basic_data_wrangling.html",
    "title": "Basic data wrangling",
    "section": "",
    "text": "Grouping and summarizing data\nWhat if we wanted to figure out monthly average temperature?\n\nmonthly_aq <- aq_df |>\n  mutate(date_2020 = as.Date(date_2020)) |> #converting chr class to Date class\n  mutate(month = month(date_2020)) |> # using month() from lubridate package\n  group_by(month) |> \n  na.omit() |>\n  summarise(avg_temp = mean(temperature))\n\nhead(monthly_aq)\n\n# A tibble: 6 × 2\n  month avg_temp\n  <dbl>    <dbl>\n1     1     69.2\n2     2     76.7\n3     3     81.7\n4     4     70.7\n5     5     71.1\n6     6     78.6\n\n\nExercise: Try grouping by two variables, month and ID (represents different sensors), and summarize by mean of average temperature and median of air quality."
  },
  {
    "objectID": "data_wrangling_continued.html",
    "href": "data_wrangling_continued.html",
    "title": "Data wrangling (continued)",
    "section": "",
    "text": "You have already used several functions. mutate(), mean(), summarize(), etc. are all functions developed for base R or other specific packages like tidyverse. Functions simplify analytics process by making code more readable and concise.\nWe can develop our own functions in R. Functions are particularly useful when we need to do the same operation multiple times. Instead of copying and pasting code every time we repeat an operation, we can write a function.\nFrom : Writing a function has three big advantages over using copy-and-paste (R for Data Science, 2e):\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\nIt makes it easier to reuse work from project-to-project, increasing your productivity over time.\n\n\n\nSuppose we want to create a function that takes a number as input, and returns the square of that number as output. Here’s how we would write the function in R.\n\nget_squared <- function(num) {\n  return (num * num)\n}\n\nget_squared(5)\n## [1] 25\nget_squared(10)\n## [1] 100\n\nExplanation:\n\nget_squared is the name of the function. It should ideally tell us what the function does concisely and follow good variable naming practices we discussed earlier.\nfunction() is the syntax to create functions.\nnum is a input to the function. Function inputs are called parameters.\nreturn specifies what the function returns as output. Not all functions have return statements, we will deal with them later in the course.\nto use the function, we write function name with inputs within the brackets as we did for get_squared(5)\n\n\n\n\nWe will work on a data of sports arenas\n\nlibrary(tidyverse)\n\nsport <- c(\"soccer\", \"football\", \"baseball\", \"basketball\", \"hockey\", \"tennis\")\nlength <- c(100, 120, 90, 94, 200, 78)\nwidth <- c(64, 53.3, 27, 50, 85, 36)\nfield_df <- data.frame(sport, length, width)\nfield_df\n##        sport length width\n## 1     soccer    100  64.0\n## 2   football    120  53.3\n## 3   baseball     90  27.0\n## 4 basketball     94  50.0\n## 5     hockey    200  85.0\n## 6     tennis     78  36.0\n\n#define a function to calculate area\narea_field <- function (length, width) {\n  return (length * width)\n}\n\n# use mutate to create a new column using the area_field function\nfield_df <- field_df %>% \n  mutate(area = area_field(length, width))\n\nhead(field_df)\n##        sport length width  area\n## 1     soccer    100  64.0  6400\n## 2   football    120  53.3  6396\n## 3   baseball     90  27.0  2430\n## 4 basketball     94  50.0  4700\n## 5     hockey    200  85.0 17000\n## 6     tennis     78  36.0  2808\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate dummy data of four places and temperatures (in Fahrenheit). Create a function to convert Fahrenheit temperature to Celsius. Use that function to create a new column of temperature in degree Celsius in your dummy data frame."
  },
  {
    "objectID": "data_wrangling_continued.html#conditionals-if_else",
    "href": "data_wrangling_continued.html#conditionals-if_else",
    "title": "Data wrangling (continued)",
    "section": "Conditionals: if_else",
    "text": "Conditionals: if_else\nIf else conditionals help us operate on data based on certain conditions. Take for example your grades. Your grades are conditioned on your scores and criteria for grading that your instructor sets.\n\nlibrary(tidyverse)\n\n# create dummy dataset\nstudents <- tibble(\n  name = c(\"AB\", \"CS\", \"ST\", \"KK\", \"UB\", \"RW\"),\n  score = c(75, 85, 90, 60, 80, 95)\n)\n\n\nCreating new columns with if_else conditions\n\nstudents <- students %>% \n  mutate(result = if_else(score >= 70, \"Pass\", \"Fail\"))\n\nstudents\n## # A tibble: 6 × 3\n##   name  score result\n##   <chr> <dbl> <chr> \n## 1 AB       75 Pass  \n## 2 CS       85 Pass  \n## 3 ST       90 Pass  \n## 4 KK       60 Fail  \n## 5 UB       80 Pass  \n## 6 RW       95 Pass\n\nAnatomy of if_else:\n\nif_else if a tidyverse function. The base R equivalent is ifelse\nthere are three components inside the bracket:\n\nscore>=70 sets a criteria\n“Pass” is the value of the new column if the criteria is True\n“Fail” is the value of the new column if the criteria is False\n\n\n\n\nAdding multiple conditions\n\nstudents <- students %>% \n  mutate(\n    grade = case_when(\n      score >= 90 ~ \"A\",\n      score >= 80 ~ \"B\",\n      score >= 70 ~ \"C\",\n      score >= 60 ~ \"D\",\n      TRUE ~ \"F\"\n    )\n  )\n\nstudents\n## # A tibble: 6 × 4\n##   name  score result grade\n##   <chr> <dbl> <chr>  <chr>\n## 1 AB       75 Pass   C    \n## 2 CS       85 Pass   B    \n## 3 ST       90 Pass   A    \n## 4 KK       60 Fail   D    \n## 5 UB       80 Pass   B    \n## 6 RW       95 Pass   A\n\nif_else is useful when we have only one condition that can be True or False. When we have multiple possible outputs for different conditions, we can use case_when.\nExercise: I wrote a process to generate dummy data of customers of an imaginary store based on the following code.\n\n# create dummy data\nset.seed(123) #ensures reproducibility\n\ncustomer <- paste0(\"Customer\", 1:10)\nage <- sample(18:65, 10, replace = TRUE)\ngender <- sample(c(\"Male\", \"Female\"), 10, replace = TRUE)\nincome <- sample(25000:100000, 10, replace = TRUE)\nspending_2020 <- sample(1000:5000, 10, replace = TRUE)\nspending_2021 <- sample(1000:5000, 10, replace = TRUE)\n\n# combine into a data frame\ncustomer_data <- data.frame(customer, age, gender, income, spending_2020, spending_2021)\n\n# view data frame\ncustomer_data\n##      customer age gender income spending_2020 spending_2021\n## 1   Customer1  48   Male  60655          2247          4936\n## 2   Customer2  32 Female  92149          1165          3906\n## 3   Customer3  31   Male  74706          1216          1152\n## 4   Customer4  20   Male  45852          2313          1293\n## 5   Customer5  59   Male  99894          3628          1276\n## 6   Customer6  60   Male  34990          3119          2486\n## 7   Customer7  54 Female  40272          1587          1040\n## 8   Customer8  31   Male  28003          2598          3478\n## 9   Customer9  42   Male  77358          1140          3137\n## 10 Customer10  43   Male  61762          1721          1315\n\nPerform the following:\n\nCreate a new variable called Total spending that is the sum of spending in 2020 and 2021\nUse an ifelse() statement and the mutate() function to create a new variable called Frequent shopper that is equal to “Yes” if a customer’s total spending is greater than $5000, and “No” otherwise.\nUse the group_by() and summarise() functions to calculate the total number of frequent shoppers by different age groups. Create three age groups based on your own judgment."
  },
  {
    "objectID": "data_wrangling_continued.html#joining-different-datasets",
    "href": "data_wrangling_continued.html#joining-different-datasets",
    "title": "Data wrangling (continued)",
    "section": "Joining different datasets",
    "text": "Joining different datasets\nIt is rare that we will be do most of our analysis using a single dataset. We usually need to combine multiple datasets to seek valuable insights. The process of combining the datasets are known as “joins.” There are various types of joins, but we will focus on the two most commonly used joins in this tutorial.\nWe will get data on population in North Carolina counties from ACS and area of different counties from TIGRIS. We will combine those datasets to be able to estimate population density in those counties.\n\n#install.packages(\"tidycensus\")\nlibrary(tidycensus)\n\n# gets latest ACS data\nnc_counties_pop <- get_acs(\n  geography = \"county\", \n  variables = \"B01003_001\",\n  state = \"NC\") |>\n  rename(population = estimate) |>\n  select(-variable, -moe)\n## Getting data from the 2016-2020 5-year ACS\n\nhead(nc_counties_pop)\n## # A tibble: 6 × 3\n##   GEOID NAME                             population\n##   <chr> <chr>                                 <dbl>\n## 1 37001 Alamance County, North Carolina      166144\n## 2 37003 Alexander County, North Carolina      37271\n## 3 37005 Alleghany County, North Carolina      11085\n## 4 37007 Anson County, North Carolina          24430\n## 5 37009 Ashe County, North Carolina           27009\n## 6 37011 Avery County, North Carolina          17510\n\n\n#install.packages(\"tigris\")\nlibrary(tigris)\noptions(tigris_use_cache = TRUE)\n\nnc_counties_area <- counties(state = \"NC\", cb = TRUE) %>% \n  mutate(area = ALAND + AWATER) %>% \n  select(GEOID, area)\n\n\nhead(nc_counties_area) \n## Simple feature collection with 6 features and 2 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32187 ymin: 34.98659 xmax: -76.01142 ymax: 36.56235\n## Geodetic CRS:  NAD83\n##    GEOID       area                       geometry\n## 92 37039 1208659098 MULTIPOLYGON (((-84.31749 3...\n## 93 37089  971465695 MULTIPOLYGON (((-82.74289 3...\n## 94 37171 1389934523 MULTIPOLYGON (((-80.97364 3...\n## 95 37131 1425923942 MULTIPOLYGON (((-77.90008 3...\n## 97 37177 1546678365 MULTIPOLYGON (((-76.4056 35...\n## 98 37043  571822258 MULTIPOLYGON (((-84.00582 3...\n\nWe can see that there is a common “GEOID” column that we can use to join the dataset.\nThere are few different joins we can use for these datasets.\n\nnc_counties <- inner_join(nc_counties_area, nc_counties_pop)\n## Joining with `by = join_by(GEOID)`\nhead(nc_counties)\n## Simple feature collection with 6 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32187 ymin: 34.98659 xmax: -76.01142 ymax: 36.56235\n## Geodetic CRS:  NAD83\n##   GEOID       area                               NAME population\n## 1 37039 1208659098    Cherokee County, North Carolina      28413\n## 2 37089  971465695   Henderson County, North Carolina     116298\n## 3 37171 1389934523       Surry County, North Carolina      71904\n## 4 37131 1425923942 Northampton County, North Carolina      19672\n## 5 37177 1546678365     Tyrrell County, North Carolina       3978\n## 6 37043  571822258        Clay County, North Carolina      11150\n##                         geometry\n## 1 MULTIPOLYGON (((-84.31749 3...\n## 2 MULTIPOLYGON (((-82.74289 3...\n## 3 MULTIPOLYGON (((-80.97364 3...\n## 4 MULTIPOLYGON (((-77.90008 3...\n## 5 MULTIPOLYGON (((-76.4056 35...\n## 6 MULTIPOLYGON (((-84.00582 3...\n\nIt joins the latter dataset (nc_counties_pop) to the nc_counties_area dataset. Since the name of the common variable (GEOID) is same between both datasets, it automatically joins by that variable.\nThe better practice is to make the common variable explicit, in case there are multiple common variables.\n\nnc_counties2 <- inner_join(nc_counties_area, nc_counties_pop, by = \"GEOID\")\nhead(nc_counties2)\n## Simple feature collection with 6 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32187 ymin: 34.98659 xmax: -76.01142 ymax: 36.56235\n## Geodetic CRS:  NAD83\n##   GEOID       area                               NAME population\n## 1 37039 1208659098    Cherokee County, North Carolina      28413\n## 2 37089  971465695   Henderson County, North Carolina     116298\n## 3 37171 1389934523       Surry County, North Carolina      71904\n## 4 37131 1425923942 Northampton County, North Carolina      19672\n## 5 37177 1546678365     Tyrrell County, North Carolina       3978\n## 6 37043  571822258        Clay County, North Carolina      11150\n##                         geometry\n## 1 MULTIPOLYGON (((-84.31749 3...\n## 2 MULTIPOLYGON (((-82.74289 3...\n## 3 MULTIPOLYGON (((-80.97364 3...\n## 4 MULTIPOLYGON (((-77.90008 3...\n## 5 MULTIPOLYGON (((-76.4056 35...\n## 6 MULTIPOLYGON (((-84.00582 3...\n\nDoes it produce the same results?\n\nhead(nc_counties == nc_counties2)\n##      GEOID area NAME population geometry\n## [1,]  TRUE TRUE TRUE       TRUE     TRUE\n## [2,]  TRUE TRUE TRUE       TRUE     TRUE\n## [3,]  TRUE TRUE TRUE       TRUE     TRUE\n## [4,]  TRUE TRUE TRUE       TRUE     TRUE\n## [5,]  TRUE TRUE TRUE       TRUE     TRUE\n## [6,]  TRUE TRUE TRUE       TRUE     TRUE\n\nInner join only returns rows when there is a match.\nWe can use left join when we want all observations of the dataset on the left side, and only the matching observations on the dataset on the right side.\n\nnc_counties3 <- left_join(nc_counties_area, nc_counties_pop, by = \"GEOID\")\nhead(nc_counties3)\n## Simple feature collection with 6 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32187 ymin: 34.98659 xmax: -76.01142 ymax: 36.56235\n## Geodetic CRS:  NAD83\n##   GEOID       area                               NAME population\n## 1 37039 1208659098    Cherokee County, North Carolina      28413\n## 2 37089  971465695   Henderson County, North Carolina     116298\n## 3 37171 1389934523       Surry County, North Carolina      71904\n## 4 37131 1425923942 Northampton County, North Carolina      19672\n## 5 37177 1546678365     Tyrrell County, North Carolina       3978\n## 6 37043  571822258        Clay County, North Carolina      11150\n##                         geometry\n## 1 MULTIPOLYGON (((-84.31749 3...\n## 2 MULTIPOLYGON (((-82.74289 3...\n## 3 MULTIPOLYGON (((-80.97364 3...\n## 4 MULTIPOLYGON (((-77.90008 3...\n## 5 MULTIPOLYGON (((-76.4056 35...\n## 6 MULTIPOLYGON (((-84.00582 3...\n\nhead(nc_counties == nc_counties3)\n##      GEOID area NAME population geometry\n## [1,]  TRUE TRUE TRUE       TRUE     TRUE\n## [2,]  TRUE TRUE TRUE       TRUE     TRUE\n## [3,]  TRUE TRUE TRUE       TRUE     TRUE\n## [4,]  TRUE TRUE TRUE       TRUE     TRUE\n## [5,]  TRUE TRUE TRUE       TRUE     TRUE\n## [6,]  TRUE TRUE TRUE       TRUE     TRUE\n\nIn this case, we have all observations matching between the two datasets. Let’s remove 5 observations from the left dataset, and check if that makes any difference.\n\nnc_counties_area_short <- nc_counties_area |> \n  slice(1:95)\n\nnc_counties4 <- left_join(nc_counties_area, nc_counties_pop, by = \"GEOID\")\n\nnrow(nc_counties4)\n## [1] 100\n\nnc_counties5 <- left_join(nc_counties_area_short, nc_counties_pop, by = \"GEOID\")\n\nnrow(nc_counties5)\n## [1] 95\n\nFor the final operation, we only have 95 counties in the table with area. With left join, now we only have 95 rows in the final table.\nIs there a right join? What does it do?\n\nnc_counties6 <- right_join(nc_counties_area_short, nc_counties_pop, by = \"GEOID\")\n\nnrow(nc_counties6)\n## [1] 100\n\nNow, we have all observations in the right dataset and only matching observations from the left dataset, which is why we have 100 observations in the final dataset.\nWe will deal with other types of joins later when we need them. Inner joins and left joins are the most commonly used joins.\nExercise: Using the following tibbles, create inner join between city_population and city_area datasets. Which observations are left out? Create right join between city_density and city employment. Which observations are left out? Write your reflections in a few sentences.\n\ncity_population <- tibble(\n  city = c(\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Philadelphia\"),\n  population = c(8398748, 3990456, 2705994, 2325502, 1567442)\n)\n\ncity_area <- tibble(\n  city = c(\"New York\", \"Los Angeles\", \"Chicago\", \"Dallas\", \"Phoenix\", \"Philadelphia\"),\n  area = c(468.9, 1302.0, 227.3, 882.9, 1339.6, 347.6)\n)\n\ncity_density <- tibble(\n  city = c(\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Dallas\", \"Phoenix\", \"Philadelphia\"),\n  density = c(17888, 3072, 11907, 2632, 2635, 1207, 4508)\n)\n\ncity_employment <- tibble(\n  city = c(\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"San Antonio\"),\n  employment_rate = c(57.1, 51.2, 52.3, 61.2, 50.1, 59.8)\n)"
  },
  {
    "objectID": "exploratory_analysis.html",
    "href": "exploratory_analysis.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "We frequently work on datasets created by others for their own needs. We gather some of those datasets when accessible to us, and explore whether the data can be useful to us or whether we can dig up useful insights from data. This process if often called Exploratory Data Analysis, and is one of the most important and frequently performed activities in (urban) analytics.\nBorrowing from R for Data Science (1e),\nEDA is an iterative cycle in which we:\nThere is no exact recipe for EDA, as it depends on answers we seek and the nature of the data. However, some operations are more frequent than others in typical EDA.\nEssentially, you perform various analytical operations to ask questions to your data depending on your need and the nature of the data. EDA is a Socratic approach in that sense."
  },
  {
    "objectID": "exploratory_analysis.html#introduction-to-data",
    "href": "exploratory_analysis.html#introduction-to-data",
    "title": "Exploratory Data Analysis",
    "section": "Introduction to data",
    "text": "Introduction to data\nSFpark is the parking demand management program in San Francisco. The data we’re using are entries and exits from public parking garages from 2011-2013, available from https://www.sfmta.com/getting-around/drive-park/demand-responsive-pricing/sfpark-evaluation\nFirst, we need to load the libraries we will be using.\n\nlibrary(tidyverse)  #library for dealing with tabular data\nlibrary(lubridate)  #library for handling dates\n\nThe data are packaged as a CSV (comma separated values) file, which is just a text file where each line is a row, and the columns are separated by commas.\n\ndf <- read_csv(\"https://github.com/kshitizkhanal7/plan372-exercises/raw/main/sfpark/data/sfpark.csv\")\n\nRows: 21261 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): usage_type, date, facility, district\ndbl (2): entries, exits\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nA peek at the data\n\nhead(df)\n## # A tibble: 6 × 6\n##   usage_type date     entries exits facility             district\n##   <chr>      <chr>      <dbl> <dbl> <chr>                <chr>   \n## 1 Transient  4/1/2011     189   161 16th and Hoff Garage Mission \n## 2 Transient  4/2/2011     175   175 16th and Hoff Garage Mission \n## 3 Transient  4/3/2011     161   182 16th and Hoff Garage Mission \n## 4 Transient  4/4/2011     126   126 16th and Hoff Garage Mission \n## 5 Transient  4/5/2011     103   105 16th and Hoff Garage Mission \n## 6 Transient  4/6/2011     128   127 16th and Hoff Garage Mission\n\nWe have six columns:\ndate: the date the data were recorded\nfacility: the garage where the data were recorded\ndistrict: the district (neighborhood) where the garage is\nusage_type: the type of payment (e.g. monthly pass, transient/hourly)\nentries, exits: the number of cars that entered and exited the garage that day that used that type of payment\nExercise: Another function to understand a data better glimpse(). Use the function and compare it with head(). What do you find?"
  },
  {
    "objectID": "exploratory_analysis.html#tests-for-data-quality",
    "href": "exploratory_analysis.html#tests-for-data-quality",
    "title": "Exploratory Data Analysis",
    "section": "Tests for data quality",
    "text": "Tests for data quality\nWe need to ensure the data is fit-for-purpose. We can check for completeness, duplication, and consistency.\n\n# Checking missing values in each column\ncolSums(is.na(df))\n## usage_type       date    entries      exits   facility   district \n##          0          0          0          0          0          0\n\nThis is a very good dataset in terms of completeness. There are no NA values.\n\n# Checking for duplicate records\nduplicated_records <- df %>%\n  filter(duplicated(.))\n\nduplicated_records\n## # A tibble: 0 × 6\n## # … with 6 variables: usage_type <chr>, date <chr>, entries <dbl>, exits <dbl>,\n## #   facility <chr>, district <chr>\n\nThere are zero duplicate rows. All observations are unique.\nWe can also check if observations have values we can expect.\n\n# Checking consistency of Age column\ndf %>%\n  filter(entries < 0 | is.integer(entries))\n## # A tibble: 0 × 6\n## # … with 6 variables: usage_type <chr>, date <chr>, entries <dbl>, exits <dbl>,\n## #   facility <chr>, district <chr>\n\nNumber of entries is not negative nor are the entries decimals."
  },
  {
    "objectID": "exploratory_analysis.html#start-with-the-simple-questions-about-data",
    "href": "exploratory_analysis.html#start-with-the-simple-questions-about-data",
    "title": "Exploratory Data Analysis",
    "section": "Start with the simple questions about data",
    "text": "Start with the simple questions about data\n\nWhat garages do we have?\n\nunique(df$facility)\n##  [1] \"16th and Hoff Garage\"      \"Civic Center Garage\"      \n##  [3] \"Ellis OFarrell Garage\"     \"Fifth and Mission Garage\" \n##  [5] \"Golden Gateway Garage\"     \"Japan Center Garage\"      \n##  [7] \"Japan Center Annex Garage\" \"Lombard Street Garage\"    \n##  [9] \"Mission Bartlett Garage\"   \"Moscone Center Garage\"    \n## [11] \"Performing Arts Garage\"    \"Sutter Stockton Garage\"   \n## [13] \"Union Square Garage\"\n\nExercise:\n\nWhere in San Francisco are they (in which districts)?\nIn your own words, what does a row of the data represent?\n\n\n\nHow many cars enter a garage on an average day\n\nmean(df$entries)\n## [1] 667.6645\n\nExercise: That may be skewed by outliers. What is the median?"
  },
  {
    "objectID": "exploratory_analysis.html#understanding-group-characteristics",
    "href": "exploratory_analysis.html#understanding-group-characteristics",
    "title": "Exploratory Data Analysis",
    "section": "Understanding group characteristics",
    "text": "Understanding group characteristics\nGrouped data analysis is a very common pattern - rather than a mean over the entire dataset, we may want a mean by groups. For instance, the median being so different from the mean suggests outliers - perhaps one very large garage. Let’s look at the mean entries by garage.\n\ndf |> \n  group_by(facility) |> \n  summarize(mean_entries=mean(entries))\n## # A tibble: 13 × 2\n##    facility                  mean_entries\n##    <chr>                            <dbl>\n##  1 16th and Hoff Garage              151.\n##  2 Civic Center Garage               333.\n##  3 Ellis OFarrell Garage             839.\n##  4 Fifth and Mission Garage         2074.\n##  5 Golden Gateway Garage             555.\n##  6 Japan Center Annex Garage         206.\n##  7 Japan Center Garage               763.\n##  8 Lombard Street Garage             132.\n##  9 Mission Bartlett Garage           298.\n## 10 Moscone Center Garage             314.\n## 11 Performing Arts Garage            274.\n## 12 Sutter Stockton Garage           1334.\n## 13 Union Square Garage               989.\n\nBut this could be misleading. Does each row represent a single day at a single garage?\nAre we actually computing the mean of above?\nWe can use the group_by and summarize functions to create a dataset that shows total entries and exits for each day, and create a new table with this information.\n\ntotal_entries <- df |>\n  group_by(date, facility) |> \n  summarize(entries=sum(entries), exits=sum(exits))\n## `summarise()` has grouped output by 'date'. You can override using the\n## `.groups` argument.\n\nhead(total_entries)\n## # A tibble: 6 × 4\n## # Groups:   date [1]\n##   date     facility                  entries exits\n##   <chr>    <chr>                       <dbl> <dbl>\n## 1 1/1/2012 16th and Hoff Garage           64    96\n## 2 1/1/2012 Civic Center Garage             3   379\n## 3 1/1/2012 Ellis OFarrell Garage        1352  1373\n## 4 1/1/2012 Fifth and Mission Garage     3566  4748\n## 5 1/1/2012 Golden Gateway Garage           5   549\n## 6 1/1/2012 Japan Center Annex Garage     431   440\n\nNow we can calculate the mean entries by garage, using this new dataset."
  },
  {
    "objectID": "exploratory_analysis.html#focusing-on-whats-interesting-to-us",
    "href": "exploratory_analysis.html#focusing-on-whats-interesting-to-us",
    "title": "Exploratory Data Analysis",
    "section": "Focusing on what’s interesting to us",
    "text": "Focusing on what’s interesting to us\nMaybe we don’t want to look at the entire city, but only at garages in the Civic Center neighborhood. We can filter the data and repeat the above analysis.\n\ncivic_center_data <- filter(df, district == \"Civic Center\")\n\nNow, repeat the above analysis to compute total entries by day, and take the daily average, using only data from Civic Center use group_by and summarize to compute means.\nRepeat the process, looking only at garages in the Mission"
  },
  {
    "objectID": "exploratory_analysis.html#handling-dates",
    "href": "exploratory_analysis.html#handling-dates",
    "title": "Exploratory Data Analysis",
    "section": "Handling dates",
    "text": "Handling dates\nAnother dimension of this dataset that we have not explored is the date column. Before we can work with dates, however, we have to parse the column.\nEvery column in a table has a type (for instance, integer, decimal number, string). read_csv tries to guess the best type for each field. We can see what types are used in our table by printing the table to the console. The types are printed just below the column names.\n\nhead(total_entries)\n## # A tibble: 6 × 4\n## # Groups:   date [1]\n##   date     facility                  entries exits\n##   <chr>    <chr>                       <dbl> <dbl>\n## 1 1/1/2012 16th and Hoff Garage           64    96\n## 2 1/1/2012 Civic Center Garage             3   379\n## 3 1/1/2012 Ellis OFarrell Garage        1352  1373\n## 4 1/1/2012 Fifth and Mission Garage     3566  4748\n## 5 1/1/2012 Golden Gateway Garage           5   549\n## 6 1/1/2012 Japan Center Annex Garage     431   440\n\nread_csv has read the date as string. These columns only store the letters, and don’t know that they represent dates. Before we can use the dates, we need to parse the dates. To parse dates, we will use the lubridate library: https://lubridate.tidyverse.org/\n\nthe mdy function parses dates in month/day/year format\n\n\ntotal_entries <- mutate(total_entries, date=mdy(date))\n\nDisplay the table again, to check the types\n\nhead(total_entries)\n## # A tibble: 6 × 4\n## # Groups:   date [1]\n##   date       facility                  entries exits\n##   <date>     <chr>                       <dbl> <dbl>\n## 1 2012-01-01 16th and Hoff Garage           64    96\n## 2 2012-01-01 Civic Center Garage             3   379\n## 3 2012-01-01 Ellis OFarrell Garage        1352  1373\n## 4 2012-01-01 Fifth and Mission Garage     3566  4748\n## 5 2012-01-01 Golden Gateway Garage           5   549\n## 6 2012-01-01 Japan Center Annex Garage     431   440\n\nLet’s look at the mean entries by year, to look for trends over time\nFirst, we need to extract the year from the date column, and assign it to a new column. We previously used mutate for this; this line uses $ notation which is another way of doing the same thing.\n\ntotal_entries$year = year(total_entries$date)\n\nMake sure it worked\n\nunique(total_entries$year)\n## [1] 2012 2013 2011\n\nNow, look at mean entries by garage and year\n\ngroup_by(total_entries, facility, year) |>\n  summarize(entries=mean(entries))\n## `summarise()` has grouped output by 'facility'. You can override using the\n## `.groups` argument.\n## # A tibble: 39 × 3\n## # Groups:   facility [13]\n##    facility                  year entries\n##    <chr>                    <dbl>   <dbl>\n##  1 16th and Hoff Garage      2011    129.\n##  2 16th and Hoff Garage      2012    162.\n##  3 16th and Hoff Garage      2013    166.\n##  4 Civic Center Garage       2011    925.\n##  5 Civic Center Garage       2012    977.\n##  6 Civic Center Garage       2013   1191.\n##  7 Ellis OFarrell Garage     2011   1736.\n##  8 Ellis OFarrell Garage     2012   1659.\n##  9 Ellis OFarrell Garage     2013   1616.\n## 10 Fifth and Mission Garage  2011   4324.\n## # … with 29 more rows\n\nThe year_totals table is in “long” format - one row for each facility for each year. It would be easier to read in “wide” format: one row for each facility and one column for each year.\nThe column names are taken from the field named in names_from, and the values from the field named in values_from now, look at mean entries by garage and year.\n\ngroup_by(total_entries, facility, year) |>\n  summarize(entries=mean(entries)) |>\n  pivot_wider(names_from=year, values_from=entries)\n## `summarise()` has grouped output by 'facility'. You can override using the\n## `.groups` argument.\n## # A tibble: 13 × 4\n## # Groups:   facility [13]\n##    facility                  `2011` `2012` `2013`\n##    <chr>                      <dbl>  <dbl>  <dbl>\n##  1 16th and Hoff Garage        129.   162.   166.\n##  2 Civic Center Garage         925.   977.  1191.\n##  3 Ellis OFarrell Garage      1736.  1659.  1616.\n##  4 Fifth and Mission Garage   4324.  4758.  4865.\n##  5 Golden Gateway Garage      1086.  1107.  1159.\n##  6 Japan Center Annex Garage   399.   416.   423.\n##  7 Japan Center Garage        1514.  1541.  1515.\n##  8 Lombard Street Garage       232.   282.   280.\n##  9 Mission Bartlett Garage     603.   595.   581.\n## 10 Moscone Center Garage       536.   654.   736.\n## 11 Performing Arts Garage      453.   522.   787.\n## 12 Sutter Stockton Garage     3189.  3205.  3090.\n## 13 Union Square Garage        2160.  2228.  2237.\n\nExercise: repeat the above, but get the per-month mean rather than per year, to show seasonal trends. You should have a table with rows for each garage and columns for January, February, etc."
  },
  {
    "objectID": "exploratory_analysis.html#testing-our-hunches",
    "href": "exploratory_analysis.html#testing-our-hunches",
    "title": "Exploratory Data Analysis",
    "section": "Testing our hunches",
    "text": "Testing our hunches\nWeekdays vs weekends Some garages may be more popular on weekdays than on weekends. We need to repeat the above analysis, but we want a mean for weekends and a mean for weekdays. Lubridate does not have a weekend function, so we need to use the day of week function to make a new weekend column. First, we can create a day of week column.\n\ntotal_entries$day_of_week <- wday(total_entries$date, label=T)\n\nLook at how the days of week are abbreviated\n\nunique(total_entries$day_of_week)\n## [1] Sun Tue Thu Wed Fri Sat Mon\n## Levels: Sun < Mon < Tue < Wed < Thu < Fri < Sat\n\nnow, we can recode that to weekday/weekend\n\ntotal_entries$weekend <- recode(total_entries$day_of_week, \n                               \"Mon\"=\"weekday\", \n                               \"Tue\"=\"weekday\", \n                               \"Wed\"=\"weekday\", \n                               \"Thu\"=\"weekday\",\n                               \"Fri\"=\"weekday\", \n                               \"Sat\"=\"weekend\", \n                               \"Sun\"=\"weekend\")\n\nhead(total_entries$weekend)\n## [1] weekend weekend weekend weekend weekend weekend\n## Levels: weekend < weekday\n\nCalculate the means\n\ngroup_by(total_entries, facility, weekend) |>\n  summarize(entries=mean(entries)) |> \n  pivot_wider(names_from=weekend, values_from=entries)\n## `summarise()` has grouped output by 'facility'. You can override using the\n## `.groups` argument.\n## # A tibble: 13 × 3\n## # Groups:   facility [13]\n##    facility                  weekend weekday\n##    <chr>                       <dbl>   <dbl>\n##  1 16th and Hoff Garage         182.    139.\n##  2 Civic Center Garage          468.   1212.\n##  3 Ellis OFarrell Garage       1754.   1647.\n##  4 Fifth and Mission Garage    5170.   4411.\n##  5 Golden Gateway Garage        810.   1229.\n##  6 Japan Center Annex Garage    473.    386.\n##  7 Japan Center Garage         1846.   1399.\n##  8 Lombard Street Garage        262.    265.\n##  9 Mission Bartlett Garage      559.    609.\n## 10 Moscone Center Garage        370.    732.\n## 11 Performing Arts Garage       444.    590.\n## 12 Sutter Stockton Garage      2409.   3484.\n## 13 Union Square Garage         2200.   2208.\n\nExercise: Compute means by season"
  },
  {
    "objectID": "exploratory_analysis.html#visualization",
    "href": "exploratory_analysis.html#visualization",
    "title": "Exploratory Data Analysis",
    "section": "Visualization",
    "text": "Visualization\nThis data would be more interesting if it were on a graph. To make graphs in R, most people use the ggplot2 library, which is part of tidyverse.\nLet us create a dataset that shows how many entries to all garages there were on each day\n\ncitywide_entries = group_by(total_entries, date) |> \n  summarize(entries=sum(entries))\n\nCreate a plot using the total_entries table. We define an “aesthetic” that the date will be the x axis, and the number of entries will be the y axis\n\nggplot(citywide_entries, aes(x=date, y=entries)) +\n  geom_line()\n\n\n\n\nWow, that’s a mess - there’s too much day-to-day variation to understand trends. Let’s group the data by month and year, and plot again\n\nthe floor_date function returns the beginning of whatever period you put in - in this case, the beginning of the month\n\n\ncitywide_entries$month_year <- floor_date(citywide_entries$date, unit=\"month\")\n\nmonthly_entries = group_by(citywide_entries, month_year) |> summarize(entries=sum(entries))\n\nggplot(monthly_entries, aes(x=month_year, y=entries)) + \n  geom_line()\n\n\n\n\nWhat month has the highest parking demand? Why do you think that is?\nThis is an interesting plot, but it would be more interesting to see it by garage. We can do this by using data that is not summed up to citywide level, an then telling ggplot to group by the facility\n\ntotal_entries$year_month = floor_date(total_entries$date, unit=\"month\")\n\ngarage_month_entries = group_by(total_entries, facility, year_month) |> \n  summarize(entries=sum(entries))\n## `summarise()` has grouped output by 'facility'. You can override using the\n## `.groups` argument.\n\nlook at the result of that call\n\ngarage_month_entries[1:20,] #looking at the first 20 observations\n## # A tibble: 20 × 3\n## # Groups:   facility [1]\n##    facility             year_month entries\n##    <chr>                <date>       <dbl>\n##  1 16th and Hoff Garage 2011-04-01    4156\n##  2 16th and Hoff Garage 2011-05-01    3996\n##  3 16th and Hoff Garage 2011-06-01    3854\n##  4 16th and Hoff Garage 2011-07-01    3777\n##  5 16th and Hoff Garage 2011-08-01    3633\n##  6 16th and Hoff Garage 2011-09-01    3599\n##  7 16th and Hoff Garage 2011-10-01    4231\n##  8 16th and Hoff Garage 2011-11-01    3877\n##  9 16th and Hoff Garage 2011-12-01    4292\n## 10 16th and Hoff Garage 2012-01-01    4411\n## 11 16th and Hoff Garage 2012-02-01    4391\n## 12 16th and Hoff Garage 2012-03-01    5184\n## 13 16th and Hoff Garage 2012-04-01    4961\n## 14 16th and Hoff Garage 2012-05-01    4959\n## 15 16th and Hoff Garage 2012-06-01    4995\n## 16 16th and Hoff Garage 2012-07-01    4991\n## 17 16th and Hoff Garage 2012-08-01    5121\n## 18 16th and Hoff Garage 2012-09-01    5240\n## 19 16th and Hoff Garage 2012-10-01    4931\n## 20 16th and Hoff Garage 2012-11-01    4878\n\nNow, plot the data but tell ggplot to group by facility, use separate colors for each facility\n\nggplot(garage_month_entries, aes(x=year_month, y=entries, group=facility, color=facility)) +\n  geom_line()\n\n\n\n\nWhich garages have more of a seasonal trend? why?\nExercise: look at weekly trends rather than monthly trends\n\nA closer look at Usage types\nThe data include several usage types - monthly passes, transient users, etc.\nExercise: first, extract all of the unique values of the usage_type column to see what the possibilities are.\n\nHow many entries are from each of the usage types? What usage type is most common?\nAre the patterns of usage types different on the weekdays vs. the weekends?\nMake a plot of the monthly trend in number of entries by usage type.\n\nCredits: This tutorials borrows heavily and expands on EDA tutorial taught in PLAN 372 Spring 2023 by Matthew Wigginton Bhagat-Conway."
  },
  {
    "objectID": "first_tutorial.html#r-as-a-scientific-calculator",
    "href": "first_tutorial.html#r-as-a-scientific-calculator",
    "title": "Your first tutorial with R and markdown",
    "section": "R as a scientific calculator",
    "text": "R as a scientific calculator\n\nAddition of two numbers\n\n2+2\n## [1] 4\n\n\n\n\n\n\n\nExercise\n\n\n\n\nUsing regular mathematical symbols (+, -, /, and *), try more complex calculations.\n\n\n\n\n\nOther mathematical functions\n\nlog(1)              # logarithm to base e\n## [1] 0\n\nlog10(1)            # logarithm to base 10\n## [1] 0\n\nexp(1)              # natural antilog\n## [1] 2.718282\n\nsqrt(4)             # square root\n## [1] 2\n\n4^2                 # 4 to the power of 2\n## [1] 16\n\npi                  # not a function but useful\n## [1] 3.141593\n\n\n\nCreating, naming, and manipulating objects\nEverything we create or manipulate using R is an object. It can range from a character “a”, a number (1), a dataset, an image, a function, and more. Essentially, all data analysis involves creating and manipulating objects.\nWe use the assignment operator <- to create objects and assign those to object names.\nWe can also use the = operator, but it’s customary to use <-. For this course, I will use <- but feel free to use =.\nFor example,\n\na <- 5\na\n## [1] 5\n\nx = 5\nx\n## [1] 5\n\nWe created an object “a” with value 5. On the top right side of RStudio, you can see a in your “Environment.”\nNow we can perform mathematical operation by manipulating the object a.\n\na * 2\n## [1] 10\n\na + a\n## [1] 10\n\na ^ a\n## [1] 3125\n\nSimilarly,\n\nb <- 10\n\n(a + b) ^ 2\n## [1] 225\n\nObjects that are often known as strings in programming (e.g. words, phrases, etc.) are assigned slightly differently.\n\nstring1 <- \"this is a string\"\nstring1\n## [1] \"this is a string\"\n\nstring2 <- \"this is another string\"\nstring2\n## [1] \"this is another string\"\n\n# joining strings\nstring3 <- paste0(string1, \" \", string2)\nstring3\n## [1] \"this is a string this is another string\"\n\n\nNaming objects\n\ncamelCase or underscores only. Example: thisNewVariable, this_new_variable\nno numbers in the beginning (not 1_alpha but alpha_1 is good)\nvariable should sufficiently represent what it’s about but be concise (for exampple, energy_df is preferable to energy_consumption_estimation_data_frame)\n\n\n\n\nWorking with data\n\nCreating a list of numbers\nc() joins (concatenates) the numbers from one to five to create a vector. A vector in R is essentially a data type that stores numbers or strings.\nThe vector can also be created using : symbol for sequences.\n== is an operator that checks if objects being compared are equal.\n\nmy_vector <- c(1, 2, 3, 4, 5)\nanother_vector <- 1:5\nmy_vector == another_vector\n## [1] TRUE TRUE TRUE TRUE TRUE\n\n\nmy_vec <- c(2, 3, 1, 6, 4, 3, 3, 7)\n\nmean(my_vec)\n## [1] 3.625\n\nlength(my_vec)\n## [1] 8\n\n\n\n\n\n\n\nExercise:\n\n\n\nIt’s almost impossible to remember all programming syntax we need. A skill to develop is to find where to look for syntax when you need. You can refer to documentation, online resources like tutorials or books, or in your Integrated Development Environment (here, RStudio).\nUse a search engine (e.g. Google) to find out how you can calculate the standard deviation of “my_vec” in R.\n\n\n\n\nExtracting values from vectors\n\nWe can use the position of elements in the vectors.\n\nmy_vec[3] #accesses the third element in the vector\n\n[1] 1\n\nmy_vec[2:5] #accesses the second to the fifth elements in the vector\n\n[1] 3 1 6 4\n\n\n\n\nWe can use conditionality\n\nmy_vec[my_vec > 4] #values greater than 4\n\n[1] 6 7\n\nmy_vec[my_vec >2 & my_vec < 8] #values greater than two and less than 8\n\n[1] 3 6 4 3 3 7\n\nmy_vec[my_vec <2 | my_vec > 6] #values less than two or more than 6\n\n[1] 1 7\n\n\n\n\n\nManipulating vectors\n\nReplacing elements\n\nmy_vec[2] <- 100 #replacing the second element by 100\nmy_vec\n\n[1]   2 100   1   6   4   3   3   7\n\n# replace element that are less than or equal to 4 with 1000\nmy_vec[my_vec <= 5] <- 200\nmy_vec\n\n[1] 200 100 200   6 200 200 200   7\n\n\n\n\nVectorization\nWe can apply an operation to all elements of the vectors at the same time. This is known as vectorization, and is very useful in data analysis to make the code more concise and readable.\n\n# create a vector\nmy_vec2 <- c(3, 5, 7, 1, 9, 20)\n\n# multiply each element by 5\nmy_vec2 * 5\n\n[1]  15  25  35   5  45 100\n\n\n\n\nMore operations\n\n# create a second vector\nmy_vec3 <- c(17, 15, 13, 19, 11, 0)\n\n# add both vectors\nmy_vec2 + my_vec3\n\n[1] 20 20 20 20 20 20\n\n# multiply both vectors\nmy_vec2 * my_vec3\n\n[1] 51 75 91 19 99  0\n\n# sort vector by values\nvec_sort <- sort(my_vec)\n\n# sort in descending order\nvec_sort2 <- sort(my_vec, decreasing = TRUE)\nvec_sort2\n\n[1] 200 200 200 200 200 100   7   6\n\n# reverse a vector\nrev_vec <- rev(my_vec)\nrev_vec\n\n[1]   7 200 200 200   6 200 100 200\n\n\n\n\nMissing data\nNA or not available is a common symbol to represent missingness in R. Missingness is when we don’t have information but there is space for that information.\n\ntemp  <- c(7.2, NA, 7.1, 6.9, 6.5, 5.8, 5.8, 5.5, NA, 5.5)\ntemp\n\n [1] 7.2  NA 7.1 6.9 6.5 5.8 5.8 5.5  NA 5.5\n\n#calculate mean\nmean_temp <- mean(temp)\nmean_temp\n\n[1] NA\n\n\nIt resulted in NA as mean because mathematical operations cannot be performed with NA values. We can remove NA using na.rm=TRUE\n\nmean_temp <- mean(temp, na.rm = TRUE)\nmean_temp\n\n[1] 6.2875\n\n\n\n\n\n\nImporting data from csv files\nWhile creating and manipulating vectors have been useful for learning fundamental concepts, we mostly work with existing dataset.\n\n# downloading data on E-ZPass Retailers Locations from NY Open Data portal using web link (URL)\ndf1 <- read.csv(\"https://data.ny.gov/api/views/y59h-w6v4/rows.csv?accessType=DOWNLOAD&sorting=true\")\nhead(df1)\n\n                              Company              Street.1  Street.2     City\n1                      DMV-HARLEM MVO 159 EAST 125TH STREET 3RD FLOOR NEW YORK\n2 COMMUNITY FINANCIAL SERVICE CENTERS   112 TOMPKINS AVENUE           BROOKLYN\n3 COMMUNITY FINANCIAL SERVICE CENTERS 1629 LEXINGTON AVENUE           NEW YORK\n4 COMMUNITY FINANCIAL SERVICE CENTERS    523 FLUSHING VENUE           BROOKLYN\n5             NYC TRANSIT MUSEUM SHOP            2 BROADWAY           NEW YORK\n6 COMMUNITY FINANCIAL SERVICE CENTERS   677 ALLERTON AVENUE              BRONX\n  State Zip.Code                 Georeference\n1    NY    10035 POINT (-73.936625 40.804046)\n2    NY    11206 POINT (-73.946317 40.695389)\n3    NY    10029  POINT (-73.94778 40.790199)\n4    NY    11205                             \n5    NY    10004  POINT (-74.01329 40.704474)\n6    NY    10467 POINT (-73.868069 40.865418)\n\n\nDownloading from your project directory\n\ndf2 <- read.csv(\"retailers_locations.csv\")\nhead(df2)\n\n                              Company              Street.1  Street.2     City\n1                      DMV-HARLEM MVO 159 EAST 125TH STREET 3RD FLOOR NEW YORK\n2 COMMUNITY FINANCIAL SERVICE CENTERS   112 TOMPKINS AVENUE           BROOKLYN\n3 COMMUNITY FINANCIAL SERVICE CENTERS 1629 LEXINGTON AVENUE           NEW YORK\n4 COMMUNITY FINANCIAL SERVICE CENTERS    523 FLUSHING VENUE           BROOKLYN\n5             NYC TRANSIT MUSEUM SHOP            2 BROADWAY           NEW YORK\n6 COMMUNITY FINANCIAL SERVICE CENTERS   677 ALLERTON AVENUE              BRONX\n  State Zip.Code                 Georeference\n1    NY    10035 POINT (-73.936625 40.804046)\n2    NY    11206 POINT (-73.946317 40.695389)\n3    NY    10029  POINT (-73.94778 40.790199)\n4    NY    11205                             \n5    NY    10004  POINT (-74.01329 40.704474)\n6    NY    10467 POINT (-73.868069 40.865418)\n\n\n\n\nAccessing columns\nWe can use the $ sign to access specific columns\n\ndf2$Company\n\n  [1] \"DMV-HARLEM MVO\"                       \n  [2] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n  [3] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n  [4] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n  [5] \"NYC TRANSIT MUSEUM SHOP\"              \n  [6] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n  [7] \"DMV-BETHPAGE MVO\"                     \n  [8] \"DMV-LOWER MANHATTAN GREENWICH MVO\"    \n  [9] \"CHECK TIME\"                           \n [10] \"AAA FARMINGDALE\"                      \n [11] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [12] \"AAA BRANFORD\"                         \n [13] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [14] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [15] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [16] \"ACTION CHECK CASHING\"                 \n [17] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [18] \"ACTION CHECK CASHING\"                 \n [19] \"RITECHECK CASHING\"                    \n [20] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [21] \"AAA EAST MEADOW\"                      \n [22] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [23] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [24] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [25] \"RITECHECK CASHING\"                    \n [26] \"CHECK TIME\"                           \n [27] \"AAA STAMFORD\"                         \n [28] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [29] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [30] \"RITECHECK CASHING\"                    \n [31] \"NYC TRANSIT MUSEUM SHOP-BROOKLYN\"     \n [32] \"DMV-HAUPPAUGE MVO\"                    \n [33] \"CHECK TIME\"                           \n [34] \"RITECHECK CASHING\"                    \n [35] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [36] \"DMV-COLLEGE POINT MVO\"                \n [37] \"RITECHECK CASHING\"                    \n [38] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [39] \"DMV-BROOKLYN MVO & LIC CTR\"           \n [40] \"DMV-MEDFORD MVO\"                      \n [41] \"THE CHECK CASHING STORE\"              \n [42] \"AAA SMITHTOWN\"                        \n [43] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [44] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [45] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [46] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [47] \"AAA BROOKLYN\"                         \n [48] \"AAA FAIRFIELD\"                        \n [49] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [50] \"RITECHECK CASHING\"                    \n [51] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [52] \"FLATLANDS CHECK CASHING\"              \n [53] \"DMV-SPRINGFIELD GARDENS MVO\"          \n [54] \"CHECK CHANGERS\"                       \n [55] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [56] \"AAA MILFORD\"                          \n [57] \"ACTION CHECK CASHING\"                 \n [58] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [59] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [60] \"AAA WATERBURY\"                        \n [61] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [62] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [63] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [64] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [65] \"AAA GARDEN CITY\"                      \n [66] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [67] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [68] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [69] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [70] \"AAA MANHATTAN\"                        \n [71] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [72] \"WEGMAN'S SUPERMARKET\"                 \n [73] \"DMV-MIDTOWN MANHATTAN MVO\"            \n [74] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [75] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [76] \"DMV-BRONX MVO\"                        \n [77] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [78] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [79] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [80] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [81] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [82] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [83] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [84] \"DMV-HUNTINGTON MVO\"                   \n [85] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [86] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [87] \"ACTION CHECK CASHING\"                 \n [88] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [89] \"DMV-BRONX LICENSING CENTER\"           \n [90] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [91] \"RITECHECK CASHING\"                    \n [92] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [93] \"AAA HAMDEN\"                           \n [94] \"RITECHECK CASHING\"                    \n [95] \"DMV-MASSAPEQUA MVO\"                   \n [96] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n [97] \"DMV-GARDEN CITY MVO\"                  \n [98] \"CHECK CHANGERS\"                       \n [99] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[100] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[101] \"RITECHECK CASHING\"                    \n[102] \"RITECHECK CASHING\"                    \n[103] \"CHECK CHANGERS\"                       \n[104] \"M&B CHECK CASHING\"                    \n[105] \"RITECHECK CASHING\"                    \n[106] \"DMV-PORT JEFFERSON MVO\"               \n[107] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[108] \"DMV-RICHMOND MVO\"                     \n[109] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[110] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[111] \"DMV-CONEY ISLAND MVO\"                 \n[112] \"DMV-RIVERHEAD MVO\"                    \n[113] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[114] \"AAA DANBURY\"                          \n[115] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[116] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[117] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[118] \"DMV-JAMAICA MVO\"                      \n[119] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[120] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[121] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[122] \"NYC TRANSIT MUSEUM SHOP-GRAND CENTRAL\"\n[123] \"RITECHECK CASHING\"                    \n[124] \"RITECHECK CASHING\"                    \n[125] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[126] \"CHECK CHANGERS\"                       \n[127] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[128] \"CHECK TIME\"                           \n[129] \"AAA NORWALK\"                          \n[130] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[131] \"CHECK TIME\"                           \n[132] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[133] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[134] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[135] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[136] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[137] \"DMV-PENN PLAZA LICENSE EXPRESS\"       \n[138] \"CHECK CHANGERS\"                       \n[139] \"CHECK CHANGERS\"                       \n[140] \"AAA QUEENS\"                           \n[141] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[142] \"BAYCHESTER PAYMENT CENTER\"            \n[143] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[144] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[145] \"QUEENS CHECK CASHING\"                 \n[146] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n[147] \"RITECHECK CASHING\"                    \n[148] \"COMMUNITY FINANCIAL SERVICE CENTERS\"  \n\nhead(df2$City) \n\n[1] \"NEW YORK\" \"BROOKLYN\" \"NEW YORK\" \"BROOKLYN\" \"NEW YORK\" \"BRONX\"   \n\n\nWe can also use the column number\n\nhead(df2[, 2])\n\n[1] \"159 EAST 125TH STREET\" \"112 TOMPKINS AVENUE\"   \"1629 LEXINGTON AVENUE\"\n[4] \"523 FLUSHING VENUE\"    \"2 BROADWAY\"            \"677 ALLERTON AVENUE\"  \n\n\nThis accesses the second column.\nBreaking down df2[ , 2]: Inside the square bracket we can mention rows and columns we want to select. dataftame[rows, columns]. Here the value for columns is 2, so second column is selected. There is no value for row, so all rows are selected.\nIf we wanted to access the first 10 rows and first 3 columns\n\ndf2[1:10, 1:3]\n\n                               Company                Street.1  Street.2\n1                       DMV-HARLEM MVO   159 EAST 125TH STREET 3RD FLOOR\n2  COMMUNITY FINANCIAL SERVICE CENTERS     112 TOMPKINS AVENUE          \n3  COMMUNITY FINANCIAL SERVICE CENTERS   1629 LEXINGTON AVENUE          \n4  COMMUNITY FINANCIAL SERVICE CENTERS      523 FLUSHING VENUE          \n5              NYC TRANSIT MUSEUM SHOP              2 BROADWAY          \n6  COMMUNITY FINANCIAL SERVICE CENTERS     677 ALLERTON AVENUE          \n7                     DMV-BETHPAGE MVO 4031 HEMPSTEAD TURNPIKE          \n8    DMV-LOWER MANHATTAN GREENWICH MVO     11 GREENWICH STREET          \n9                           CHECK TIME           2966 AVENUE U          \n10                     AAA FARMINGDALE    915 BROADHOLLOW ROAD          \n\n\nWe know how the colon sign works from the part on vectors.\n\n\n\n\n\n\nExercise:\n\n\n\nSubset the third to ninth rows and the second and third columns.\n\n\n\n\nAdd image in markdown document\nCopy the code between the inverted commas in the markdown document, not in the code chunk!\n\n\"\n![R logo](https://www.r-project.org/Rlogo.png)\n\"\n\n[1] \"\\n![R logo](https://www.r-project.org/Rlogo.png)\\n\"\n\n\n\n\n\nR logo\n\n\n\n\n\n\n\n\nExercise:\n\n\n\nDownload an image from the internet into your project directory. Embed that to the markdown."
  },
  {
    "objectID": "first_tutorial.html#writing-better-markdown",
    "href": "first_tutorial.html#writing-better-markdown",
    "title": "Your first tutorial with R and markdown",
    "section": "Writing better markdown",
    "text": "Writing better markdown\nMarkdown allows you to write aesthetic documents by following simple rules.\n\n\n\n\n\n\nExercise:\n\n\n\nRefer to markdown basics documentation and try the following:\n\nInsert one link\nInsert one list\nInsert text in bold and italics"
  },
  {
    "objectID": "first_tutorial.html#lab-submission",
    "href": "first_tutorial.html#lab-submission",
    "title": "Your first tutorial with R and markdown",
    "section": "Lab submission",
    "text": "Lab submission\nTo submit the lab, zip qmd file, html file, and the folder that has contents for html files into a single zipped folder and submit as your lab."
  },
  {
    "objectID": "fundamental_data_viz.html",
    "href": "fundamental_data_viz.html",
    "title": "Fundamentals of data visualization",
    "section": "",
    "text": "Data visualization helps us mainly with the two analytical goals:\nWe have already used the ggplot to help us with EDA. In this tutorial, we will focus more on making sense of data using plots, exploring the use of ggplot2, a popular data visualization library used by the R community."
  },
  {
    "objectID": "fundamental_data_viz.html#understanding-relationships-between-variables",
    "href": "fundamental_data_viz.html#understanding-relationships-between-variables",
    "title": "Fundamentals of data visualization",
    "section": "Understanding relationships between variables",
    "text": "Understanding relationships between variables\nWe will work with Chicago benchmarking data."
  }
]